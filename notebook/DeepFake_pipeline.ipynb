{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepFake_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "23a6ccbb213c47419c472e74538d6744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32542f92d0794668aa723cd047de6af3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7e735a81c53645fbbc1c2d06cfa8443c",
              "IPY_MODEL_8d29d1dde1c24030a0d39e543a07ac07"
            ]
          }
        },
        "32542f92d0794668aa723cd047de6af3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e735a81c53645fbbc1c2d06cfa8443c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f246c29ee32d4e1e87e6fe04f09d922c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 18,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68c2bb40463d4bfe9471de4b62e8da8f"
          }
        },
        "8d29d1dde1c24030a0d39e543a07ac07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_66a4fce7143e48ce96dd421058fbb0e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  4% 18/400 [00:01&lt;00:29, 13.12it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61936e39d4c64093b9549532223c39c6"
          }
        },
        "f246c29ee32d4e1e87e6fe04f09d922c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68c2bb40463d4bfe9471de4b62e8da8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66a4fce7143e48ce96dd421058fbb0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61936e39d4c64093b9549532223c39c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QFA9RTao7lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKhnOnCp9U06",
        "colab_type": "text"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_-aTqTn9W8F",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   There are 300 frames in a 10 second video. \n",
        "    * Instead of getting each frames, we can average every _n_ frames.\n",
        "*   The background in each video is non-relevant.\n",
        "    * Need to add a face/body detection layer and crop the frames accrodingly.\n",
        "* Need to capture movements between frames. Could use RNN, or feeding the difference between two consecutive frames\n",
        "* Add the attention maps (Stehuawer paper) inside XceptionNet blocks.\n",
        "* Frame sizes are `(1080, 1920)` and `(1920, 1080)`. Rotate the latter ones to make every frame into the same shape.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or82lwTxpuil",
        "colab_type": "text"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWr6TODopxyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f2349278-1f53-4a48-a7f2-4acdf87032cb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pxe12Iep0OR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1979f031-21a4-4598-a3cc-d0462fc2f297"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BVuu-63p_Am",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3fd0f59-21b3-4e91-c8f6-8f3465e15272"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTxvDrnUqgsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "53d74cdd-9f56-42c4-d1f2-482f56b2075e"
      },
      "source": [
        "!ls drive/My\\ Drive/DeepFake"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_submission.csv  train_sample_videos\n",
            "test_videos\t       xception_weights_tf_dim_ordering_tf_kernels.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w4N6UMu3mwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8Y2tTYp3n2U",
        "colab_type": "text"
      },
      "source": [
        "# utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwBW--Nb3k9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# play a video\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/content/drive/My Drive/DeepFake/train_sample_videos/aapnvogymq.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSbQI3nx7s_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting the number of frames in a video file\n",
        "a = cv.VideoCapture('/content/drive/My Drive/DeepFake/train_sample_videos/cdaxixbosp.mp4')\n",
        "a.get(cv.CAP_PROP_FRAME_COUNT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PdXaC4rqCf1",
        "colab_type": "text"
      },
      "source": [
        "# XceptionNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvf4CQluqFqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
        "#from tensorflow.keras.applications.imagenet_utils import _obtain_input_shape\n",
        "from tensorflow.keras.utils import get_file\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "# from tensorflow.keras.utils import np_utils\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import os\n",
        "import h5py\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "#import cv2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from skimage import io, transform\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy import misc\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRZNjzQiqIuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the path for pretrained model\n",
        "WEIGHTS_PATH = '/content/drive/My Drive/DeepFake/models/xception_weights_tf_dim_ordering_tf_kernels.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhK-eOF_q-m1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "\n",
        "def Xception(nb_classes):\n",
        "\n",
        "    # Determine proper input shape\n",
        "#     input_shape = _obtain_input_shape(None, default_size=299, min_size=71, data_format='channels_last', include_top=False)\n",
        "\n",
        "#     img_input = Input(shape=input_shape)\n",
        "    img_input = Input(shape=(227,227,3))\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False)(img_input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64, (3, 3), use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    residual = Conv2D(128, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    # Block 2\n",
        "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Block 2 Pool\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "    residual = Conv2D(256, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    # Block 3\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Block 3 Pool\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "    residual = Conv2D(728, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    # Block 4\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "    # Block 5 - 12\n",
        "    for i in range(8):\n",
        "        residual = x\n",
        "\n",
        "        x = Activation('relu')(x)\n",
        "        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = layers.add([x, residual])\n",
        "\n",
        "    residual = Conv2D(1024, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    # Block 13\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Block 13 Pool\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "    # Block 14\n",
        "    x = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Block 14 part 2\n",
        "    x = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1000, activation='relu')(x)\n",
        "    x = Dense(nb_classes, activation='softmax')(x)\n",
        "\n",
        "    inputs = img_input\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs, x, name='xception')\n",
        "\n",
        "    # Download and cache the Xception weights file\n",
        "    #weights_path = get_file('xception_weights.h5', WEIGHTS_PATH, cache_subdir='models')\n",
        "\n",
        "    # load weights\n",
        "    #model.load_weights(weights_path)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# \"\"\"\n",
        "#     Instantiate the model by using the following line of code\n",
        "\n",
        "#     model = Xception()\n",
        "\n",
        "# \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax9IXXuCrBgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwVROc1zBkmE",
        "colab_type": "text"
      },
      "source": [
        "# Simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEe07h50Bovz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "from functools import partial\n",
        "\n",
        "def simple_cnn(nb_classes):\n",
        "    DefaultConv2D = partial(Conv2D,\n",
        "                            kernel_size=3, activation='relu', padding=\"SAME\")\n",
        "    \n",
        "    model = keras.models.Sequential([\n",
        "        DefaultConv2D(filters=64, kernel_size=7, input_shape=[512, 512, 3]),\n",
        "        MaxPooling2D(pool_size=2),\n",
        "        DefaultConv2D(filters=128),\n",
        "        DefaultConv2D(filters=128),\n",
        "        MaxPooling2D(pool_size=2),\n",
        "        DefaultConv2D(filters=256),\n",
        "        DefaultConv2D(filters=256),\n",
        "        MaxPooling2D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(units=128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(units=64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(units=nb_classes, activation='softmax'),\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPBCUPRnrPt1",
        "colab_type": "text"
      },
      "source": [
        "# DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZVlgWilrWm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook\n",
        "%matplotlib inline \n",
        "import cv2 as cv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxiM85uJrdnK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b276faf8-172a-410a-e34d-5ad734733420"
      },
      "source": [
        "DATA_FOLDER = '/content/drive/My Drive/DeepFake'\n",
        "TRAIN_SAMPLE_FOLDER = 'train_sample_videos'\n",
        "TEST_FOLDER = 'test_videos'\n",
        "\n",
        "print(f\"Train samples: {len(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))}\")\n",
        "print(f\"Test samples: {len(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER)))}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train samples: 401\n",
            "Test samples: 400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqrr-FXmrz3d",
        "colab_type": "text"
      },
      "source": [
        "## Meta data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJknAwAqrmEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "99e06746-6d75-4f7b-dd6c-5889d26847d9"
      },
      "source": [
        "def get_meta_from_json(path):\n",
        "    df = pd.read_json(os.path.join(DATA_FOLDER, path, json_file))\n",
        "    df = df.T\n",
        "    return df\n",
        "\n",
        "train_list = list(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))\n",
        "test_list = list(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER)))\n",
        "json_file = [file for file in train_list if  file.endswith('json')][0]\n",
        "meta_train_df = get_meta_from_json(TRAIN_SAMPLE_FOLDER)\n",
        "meta_train_df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "      <th>original</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>aagfhgtpmv.mp4</th>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>vudstovrck.mp4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aapnvogymq.mp4</th>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>jdubbvfswz.mp4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abarnvbtwb.mp4</th>\n",
              "      <td>REAL</td>\n",
              "      <td>train</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abofeumbvv.mp4</th>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>atvmxvwyns.mp4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abqwwspghj.mp4</th>\n",
              "      <td>FAKE</td>\n",
              "      <td>train</td>\n",
              "      <td>qzimuostzz.mp4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               label  split        original\n",
              "aagfhgtpmv.mp4  FAKE  train  vudstovrck.mp4\n",
              "aapnvogymq.mp4  FAKE  train  jdubbvfswz.mp4\n",
              "abarnvbtwb.mp4  REAL  train            None\n",
              "abofeumbvv.mp4  FAKE  train  atvmxvwyns.mp4\n",
              "abqwwspghj.mp4  FAKE  train  qzimuostzz.mp4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeCpr5SLuISx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e667b3c9-d01e-41a0-cfbb-b25267d8b868"
      },
      "source": [
        "meta_train_df[\"original\"].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "meawmsgiti.mp4    6\n",
              "atvmxvwyns.mp4    6\n",
              "kgbkktcjxf.mp4    5\n",
              "qeumxirsme.mp4    5\n",
              "gjypopglvi.mp4    4\n",
              "                 ..\n",
              "dkuayagnmc.mp4    1\n",
              "ngdswpaqnt.mp4    1\n",
              "ohnonevlro.mp4    1\n",
              "vmospzljws.mp4    1\n",
              "ixuouyigxa.mp4    1\n",
              "Name: original, Length: 209, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQv3uJ1YxH3V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fac657e-132b-446f-b3a6-1c267611d55d"
      },
      "source": [
        "meta_train_df.loc[meta_train_df.index == \"aagfhgtpmv.mp4\", \"label\"].values[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'FAKE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8tAaJ6quep9",
        "colab_type": "text"
      },
      "source": [
        "# Train/Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiCtbQdG1gO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "23a6ccbb213c47419c472e74538d6744",
            "32542f92d0794668aa723cd047de6af3",
            "7e735a81c53645fbbc1c2d06cfa8443c",
            "8d29d1dde1c24030a0d39e543a07ac07",
            "f246c29ee32d4e1e87e6fe04f09d922c",
            "68c2bb40463d4bfe9471de4b62e8da8f",
            "66a4fce7143e48ce96dd421058fbb0e9",
            "61936e39d4c64093b9549532223c39c6"
          ]
        },
        "outputId": "1c0be076-18fe-4360-97cc-26375f1a2282"
      },
      "source": [
        "def walkdir(dirpath):\n",
        "    for root, dirs, files in os.walk(dirpath):\n",
        "        for name in files:\n",
        "            if name != 'metadata.json':\n",
        "                yield os.path.abspath(os.path.join(dirpath, name))\n",
        "\n",
        "filescount = meta_train_df.index.nunique()\n",
        "\n",
        "cnt = 1\n",
        "X_train_full, y_train_full = [], []\n",
        "for path in tqdm_notebook(walkdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)), total=filescount):\n",
        "    if cnt < 20:\n",
        "        capture_image = cv.VideoCapture(path) \n",
        "        ret, frame = capture_image.read()\n",
        "        if ret:\n",
        "            image = np.array(tf.image.resize(frame, [512, 512]))\n",
        "            X_train_full.append(image)\n",
        "            label = 0\n",
        "            if meta_train_df.loc[meta_train_df.index == name, \"label\"].values[0] == 'REAL':\n",
        "                label = 1\n",
        "            y_train_full.append(label)\n",
        "        cnt += 1\n",
        "    else:\n",
        "        break"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23a6ccbb213c47419c472e74538d6744",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8qTiedYuqtC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "233ef021-3f31-4c6c-f725-258ba0d1dd86"
      },
      "source": [
        "print(f\"X_train size: {len(X_train_full)}, y_train size: {len(y_train_full)}\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train size: 19, y_train size: 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJB6LXE5JIpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train_full = np.array(X_train_full)\n",
        "# y_train_full = np.array(y_train_full)\n",
        "\n",
        "split = 0.7\n",
        "cutoff = int(split * len(X_train_full))\n",
        "\n",
        "X_train, X_valid = X_train_full[:-cutoff], X_train_full[-cutoff:]\n",
        "y_train, y_valid = y_train_full[:-cutoff], y_train_full[-cutoff:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnxHOowPGQit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train_full = np.array(X_train_full)\n",
        "# y_train_full = np.array(y_train_full)\n",
        "\n",
        "# split = 0.7\n",
        "# cutoff = int(split * len(X_train))\n",
        "\n",
        "# X_train, X_valid = X_train_full[:-cutoff], X_train_full[-cutoff:]\n",
        "# y_train, y_valid = y_train_full[:-cutoff], y_train_full[-cutoff:]\n",
        "\n",
        "# X_mean = X_train.mean(axis=0, keepdims=True)\n",
        "# X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
        "# X_train = (X_train - X_mean) / X_std\n",
        "# X_valid = (X_valid - X_mean) / X_std\n",
        "# # X_test = (X_test - X_mean) / X_std\n",
        "\n",
        "# X_train = X_train[..., np.newaxis]\n",
        "# X_valid = X_valid[..., np.newaxis]\n",
        "# # X_test = X_test[..., np.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJEMbdmqGllW",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5mCoiLZGoLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = simple_cnn(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mYHKu3c7rGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "94b980a9-9088-44f1-9ce7-0f820c19038b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 512, 512, 64)      9472      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 256, 256, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 256, 256, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 256, 256, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 128, 128, 256)     295168    \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 128, 128, 256)     590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 64, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1048576)           0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               134217856 \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 135,342,337\n",
            "Trainable params: 135,342,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sY4I8HKGrxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUbwjBcjU2bV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "054d2e93-e3d3-45d2-c817-8b8cfa256e69"
      },
      "source": [
        "from sklearn.utils.validation import column_or_1d\n",
        "X_train_, y_train_ = np.array(X_train), column_or_1d(y_train)\n",
        "X_valid_, y_valid_ = np.array(X_valid), column_or_1d(y_valid)\n",
        "history = model.fit(X_train_, y_train_, batch_size=2, epochs=10, validation_data=[X_valid_, y_valid_])\n",
        "# score = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6 samples, validate on 13 samples\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 49s 8s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 46s 8s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 46s 8s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 46s 8s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 46s 8s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 46s 8s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 47s 8s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 48s 8s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 48s 8s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 51s 8s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIL8fra2Jhk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODELS_FOLDER = '/content/drive/My Drive/DeepFake/models'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v46YI5k_G14Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_NAME = 'simple_cnn_test1.h5'\n",
        "model.save_weights(os.path.join(MODELS_FOLDER, MODEL_NAME))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}